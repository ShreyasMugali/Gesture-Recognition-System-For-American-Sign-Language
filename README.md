# Gesture-Recognition-System-For-American-Sign-Language

CSE 572 Data Mining Group 14

Introduction

This project is part of the Data Mining course taken by Dr. Ayan Banerjee in the Spring of 2018. The project solves the issue of a machine-level understanding of gesture recognition with the help of data from different sensors. The gestures are taken from a standard source American Sign Language and we need to analyze the input data from sensors to distinguish between 10 different gestures- About, And, Can, Cop, Deaf, Decide, Father, Find, Go Out, Hearing.

Assignment 1: Data collection
This phase of the project involved performing the different gestures using the Myo bands(Wristband Sensor) which record the data in terms of time series.

Assignment 2: Feature Extraction and Feature Selection
This phase comprises of the following three tasks to analyze the given gestures: - Annotation, Feature Extraction Method, Feature Selection Method.

Assignment 3: User dependent analysis
This phase involved classifying different actions performed by each user into corresponding gestures using some of the machine learning techniques like decision tree, support vector machine and neural network.

Assignment 4: User independent analysis
This phase involved classifying different actions performed by all users into corresponding gestures using some of the machine learning techniques like decision tree, support vector machine and neural network.

Software: MATLAB

